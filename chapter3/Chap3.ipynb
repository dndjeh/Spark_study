{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 저수준의 RDD API 패턴과 고수준 RDD API 패턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 저수준 DSL, 데이터프레임 API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Denny', 31.0), ('TD', 35.0), ('Brooke', 22.5), ('Jules', 30.0)]\n"
     ]
    }
   ],
   "source": [
    "# RDD를 이용한 예제\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# (name, age) 형태의 튜플로 된 RDD를 생성한다.\n",
    "dataRDD = sc.parallelize([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)])\n",
    "\n",
    "# 집계와 평균을 위한 람다 표현식과 함께 map, reduceByKey 트랜스포메이션 사용용\n",
    "ageRDD = (dataRDD\n",
    "          .map(lambda x: (x[0], (x[1], 1)))\n",
    "          .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "          .map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
    "          )\n",
    "print(ageRDD.collect())\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>고수준 DSL, 데이터프레임 API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Denny|    31.0|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "\n",
    "data_df = spark.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35), (\"Brooke\", 25)], ['name', 'age'])\n",
    "avg_df = data_df.groupBy('name').agg(avg('age'))\n",
    "avg_df.show()\n",
    "input(\"Press Enter to terminate...\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 스키마 정의 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 프로그래밍 스타일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType([StructField('author', StringType(), False),\n",
    "                     StructField('title',StringType(), False),\n",
    "                     StructField('pages',IntegerType(),False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('author', StringType(), False), StructField('title', StringType(), False), StructField('pages', IntegerType(), False)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> DDL 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'author STRING, title STRING, pages INT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'author STRING, title STRING, pages INT'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
